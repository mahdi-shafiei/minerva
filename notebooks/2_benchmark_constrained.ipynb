{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from minerva.bayesopt import BayesianOptimisation "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook 2: Running a batch constrained bayesian optimisation benchmark on a virtual benchmark dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set device, use gpu if available\n",
    "tkwargs = {\n",
    "        \"dtype\": torch.double,\n",
    "        \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This tutorial shows how to run a constrained Bayesian optimisation benchmark on the emulated virtual benchmark datasets in the manuscript. The datasets are constructed as tables of concatenated descriptor representations and objective values. This follows similar instructions as `benchmark_baseline.ipynb`**\n",
    "- Constrained benchmarks restrict the number of unique values of a specific feature for each batch, e.g. only 2 unique temperatures per batch, etc.\n",
    "\n",
    "\n",
    "\n",
    "First, as in `1_benchmark_baseline.ipynb`, we show an example of a benchmark dataset.\n",
    "- The benchmark dataset is a table of rows containing the featurised representation of the reaction conditions and their corresponding objective values, in this case yield and turnover\n",
    "- The input features and target objectives are **not assumed to have undergone any scalarisation**\n",
    "- No other columns besides the input features and objective columns are assumed to be present\n",
    "- **Maximisation is assumed**, so minimisation objectives will have to be adjusted to their negative values\n",
    "- In this case, the reaction conditions consist of choice of ligand, which is one-hot encoded, with continuous variables residence time, reaction temperature, and catalyst loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suzuki_i_benchmark = pd.read_csv('../benchmark_datasets/olympus_suzuki/suzuki_i.csv', index_col=0)\n",
    "suzuki_i_benchmark\n",
    "\n",
    "# define index of temperature column in the dataframe\n",
    "temperature_index = 8"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then define the settings that we wish to run the Bayesian Optimisation benchmark on.\n",
    "\n",
    "| Arguments | Explanation |\n",
    "| --- | --- |\n",
    "| `seed` (int) | Random seed set using pytorch lightning |\n",
    "| `objective_columns` (List[str]) | List of strings denoting objective columns in the benchmark dataset |\n",
    "| `benchmark_path` (str) | File path to read the benchmark dataset file, example shown above <br> The virtual benchmark datasets used in the manuscript are included in this repository under minerva/benchmark_datasets |\n",
    "| `init_samples` (int) | Number of quasi-random Sobol samples to initialise the optimisation campaign as initial training data |\n",
    "| `batch_size` (int) | Number of experiments to suggest in parallel per iteration |\n",
    "| `n_iterations` (int) | Number of iterations to run Bayesian optimisation for, excluding the quasi-random initialisation |\n",
    "| `search_strategy` (str) | Acquisition function to use. Available choices are `qNEHVI`, `qNParEgo`, and `TS-HVI` |\n",
    "| `constrain_strategy` (int) | Strategy to use for constraining (e.g.) the number of temperatures per batch. <br> Choices implemented are `nested` and `naive`. For a full explanation we refer the user to our manuscript. |\n",
    "| `n_unique_features` (int) | The number of unique features (temperature in this case) values allowed per batch. |\n",
    "| `feature_index` (int) | Index of the constrained feature, temperature, in the training input features **tensor**. <br> This depends on your benchmark dataset and must be changed. We have added the feature indexes for our existing datasets |\n",
    "| `kernel` (str) | Kernel hyperparamters for Matern Kernel Gaussian Process. <br> Available choices are `default` and `edboplus` |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1 \n",
    "objective_columns = ['yield', 'turnover'] # defining objective columns in the dataframe to be read and optimised in the benchmark dataframe\n",
    "benchmark_path = '../benchmark_datasets/olympus_suzuki/suzuki_i.csv' \n",
    "\n",
    "init_samples = 24 \n",
    "batch_size = 24 \n",
    "n_iterations = 4 # iterations of BO in addition to initialisation we would like to run, total 24 + 24*4 = 120 in this case\n",
    "search_strategy = 'qNEHVI' \n",
    "constrain_strategy = 'nested' # strategy to use for constraining features, can be chosen from ['nested', 'naive']\n",
    "n_unique_features = 2 # number of unique features e.g. temperature allowed per batch \n",
    "kernel = 'edboplus' # choose kernel hyperparameters used in edboplus\n",
    "\n",
    "# get the feature index at which the constrained temperature is in the training data, this is dependent on dataset\n",
    "benchmark = 'olympus_suzuki'\n",
    "if benchmark == 'olympus_suzuki':\n",
    "    feature_index = 8 # this is equal to temperature_index\n",
    "elif benchmark == 'edbo_arylation':\n",
    "    feature_index = 1\n",
    "# you will need to set your own feature index for your custom datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialisation of BO object\n",
    "Benchmark = BayesianOptimisation(device=tkwargs,seed=seed)\n",
    "Benchmark.load_and_preprocess_benchmark(data_df_path=benchmark_path, objective_columns=objective_columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run the Bayesian optimisation**\n",
    "- Output metrics are displayed as hypervolume per iteration of optimisation from iteration 0 (sobol) to iteration n of the Bayesian optimisation. \n",
    "- Reference max hypervolumes of the existing dataset are also displayed\n",
    "- IGD+ and IGD metrics are also calculated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Benchmark.run_constrained_benchmark(\n",
    "    init_samples=init_samples,\n",
    "    batch_size=batch_size,\n",
    "    n_iterations=n_iterations,\n",
    "    search_strategy=search_strategy,\n",
    "    constrain_strategy=constrain_strategy,\n",
    "    n_unique_features=n_unique_features,\n",
    "    feature_index=feature_index,\n",
    "    kernel='edboplus',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b02a12b6e09d04984cc20cb4777fb86fe654b18631361ce47d6857a6f00214fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
