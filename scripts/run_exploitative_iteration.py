"""
Run iteration of exploitative ML optimisation from training data.

This script was used to perform exploitative optimisation for the final iteration of the
the HTE reaction optimisation campaign described in the manuscript associated with this
code repository.

It loads all the training data generated thus far from iterations 1 to 4, processes it,
and suggests the next round of experiments to maximise reaction objectives.
"""

import argparse
from typing import Dict, Any, Tuple

import torch
import pandas as pd

from minerva.utils import get_index_from_lookup
from minerva.bayesopt import BayesianOptimisation

# Constants
TRAIN_DATA_PATH = "../experimental_campaigns/experiments/publication/ML_training_data/ML_plate_1234_train_data.csv"
CHEM_SPACE_PATH = "../experimental_campaigns/design_spaces/ni_suzuki_chemical_space.csv"
DESCRIPTOR_INDEX = (
    7  # our reaction condition representation starts from column 7 in chem_space
)
OBJECTIVE_COLUMNS = ["P_A%", "Selectivity_A%"]


def load_training_data() -> pd.DataFrame:
    """
    Loads all training data collected in the campaign from iterations 1 to 4
    for the final exploitative iteration.
    """
    return pd.read_csv(TRAIN_DATA_PATH, index_col=0)


def load_chemical_space() -> pd.DataFrame:
    """Load the pre-defined chemical space."""
    return pd.read_csv(CHEM_SPACE_PATH, index_col=0)


def preprocess_data(
    plate_data: pd.DataFrame, chem_space: pd.DataFrame, tkwargs: Dict[str, Any]
) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
    """
    Preprocess the data for Exploitative Optimization.

    We first obtain the featurised chemical space representation, 
    and convert into a torch tensor.

    We then obtain normalised train_x and 
    unstandardised train_y for input into optimisation workflow.

    Returns (Tuple[torch.Tensor, torch.Tensor, torch.Tensor]):
    - X_main (torch.Tensor): Featurised search space to evaluate ML model over
    - train_x (torch.Tensor): Normalised training inputs of already conducted experiments
    - train_y (torch.Tensor): Unstandardised training outputs of already conducted experiments

    """
    # we obtain the featurised chemical space representation from the chemical space dataframe
    chem_descriptors = chem_space.iloc[:, DESCRIPTOR_INDEX:]

    # we convert the featurised chemical space into a tensor
    X_main = torch.tensor(chem_descriptors.to_numpy()).to(**tkwargs)

    # get train_x, which is already normalised
    plate_data.drop(labels=["rxn_id"], axis=1, inplace=True)
    columns_regression = plate_data.columns.drop(OBJECTIVE_COLUMNS).to_list()
    train_x = torch.tensor(plate_data[columns_regression].to_numpy()).to(**tkwargs)

    # get unstandardised train_y for Utopia point distance calculation
    train_y = plate_data[OBJECTIVE_COLUMNS].to_numpy()

    return X_main, train_x, train_y


def main(args):
    """Run exploitative iteration."""
    tkwargs = {
        "dtype": getattr(torch, args.dtype),
        "device": torch.device(args.device),
    }

    # load plate training_data
    plate_data = load_training_data()

    # get already conducted reactions
    conducted_experiments = plate_data["rxn_id"]

    # load chemical reaction space and remove already conducted experiments
    chem_space = load_chemical_space()
    chem_space = chem_space[~chem_space["rxn_id"].isin(conducted_experiments)]

    X_main, train_x, train_y = preprocess_data(plate_data, chem_space, tkwargs)

    Campaign = BayesianOptimisation(device=tkwargs, seed=args.seed)

    new_x = Campaign.run_exploitative_iteration(
        train_x=train_x,
        train_y=train_y,
        x_space=X_main,
        batch_size=args.batch_size,
        kernel=args.kernel,
        constrain=True,
        n_unique_features=args.n_unique_features,
        feature_index=args.feature_index,
    )

    new_index = get_index_from_lookup(new_x, X_main)
    plate_df = chem_space.iloc[new_index]
    plate_df = plate_df.iloc[:, :DESCRIPTOR_INDEX]
    print(plate_df)
    plate_df.to_csv("ML_plate_5b_suggestions.csv")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Run Exploitative Optimization")
    parser.add_argument("--seed", type=int, default=49, help="Seed for reproducibility")
    parser.add_argument(
        "--dtype", type=str, default="double", help="Data type for PyTorch tensors"
    )
    parser.add_argument(
        "--device",
        type=str,
        default="cuda" if torch.cuda.is_available() else "cpu",
        help="Device to use for computations",
    )

    # optimisation settings
    parser.add_argument(
        "--batch_size",
        type=int,
        default=96,
        help="Batch size for Exploitative optimisation",
    )
    parser.add_argument(
        "--n_unique_features",
        type=int,
        default=2,
        help="Number of allowed unique values of constrained features in a batch",
    )
    parser.add_argument(
        "--feature_index",
        type=int,
        default=-1,
        help="index of feature in X to be constrained, e.g. temperature",
    )
    parser.add_argument(
        "--kernel",
        type=str,
        default="edboplus",
        help="Kernel hyperparameter for Gaussian Process",
    )

    args = parser.parse_args()
    main(args)
